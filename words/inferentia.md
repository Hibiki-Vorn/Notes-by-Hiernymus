1. **Definition**  
	- *n.*（专有名词）亚马逊 AWS 开发的机器学习推理芯片  
	- *n.* 专用于加速人工智能模型推理（inference）的硬件  

2. **Example Sentence**  
	- 1. AWS **Inferentia** is optimized for high-performance deep learning inference.  
			AWS Inferentia 专为高性能深度学习推理优化。  
	- 2. Using **Inferentia** can significantly reduce the cost of model deployment.  
			使用 Inferentia 能大幅降低模型部署成本。  
	- 3. The **Inferentia** chip achieves low-latency predictions in real-time applications.  
			Inferentia 芯片在实时应用中实现低延迟预测。  

3. **Related Terms**  
	- 1. machine learning (机器学习)  
	- 2. inference (推理)  
	- 3. TPU (Tensor Processing Unit) 张量处理器  
	- 4. GPU (Graphics Processing Unit) 图形处理器  

4. **Antonym**  
	- *Conceptual opposites*:  
			1. general-purpose CPU 通用 CPU  
			2. training-focused hardware 训练专用硬件  